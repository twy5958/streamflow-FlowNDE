2024-10-30 15:02:57.234 | INFO     | __main__:main:137 - {'remote': False, 'device': 0, 'epochs': 200, 'seed': 42, 'batch_size': 4, 'filename': 'changjiang', 'train_ratio': 0.6, 'valid_ratio': 0.2, 'his_length': 12, 'pred_length': 12, 'num_layers': 1, 'lr': 0.001, 'step_size': 1, 'hidden_dim': 64, 'back': 3, 'thres': 0.005, 'station': 'train', 'log': 'FALSE'}
2024-10-30 15:09:13.027 | INFO     | __main__:main:190 - =====Epoch 1=====

##on train data## total loss: 0.09355805157612877, pred loss: 0.06638693612253264, regression loss: 0.027171115453596118 
##on train data## rmse loss: 2122.7460189664425, mae loss: 1171.3725209889678, mape loss: 8892.200398082055
##on valid data## rmse loss: 1713.9290696074142, mae loss: 1125.6189135695056, mape loss: 1116.8424249385776
##on test data## rmse loss: 1956.1211721059437, mae loss: 1265.4127702749834, mape loss: 600.1203207263155

2024-10-30 15:15:29.613 | INFO     | __main__:main:190 - =====Epoch 2=====

##on train data## total loss: 0.05326395472074353, pred loss: 0.045917475559431965, regression loss: 0.007346479161311565 
##on train data## rmse loss: 2009.9044656511492, mae loss: 1107.151110266671, mape loss: 1822.2037670197826
##on valid data## rmse loss: 1648.9603755759456, mae loss: 1030.325018687598, mape loss: 308.1550750032815
##on test data## rmse loss: 1844.7113691057477, mae loss: 1151.0137018034357, mape loss: 226.46642504511652

2024-10-30 15:21:33.567 | INFO     | __main__:main:190 - =====Epoch 3=====

##on train data## total loss: 0.04997245658326156, pred loss: 0.0441517535951872, regression loss: 0.005820702988074367 
##on train data## rmse loss: 1990.5762497955168, mae loss: 1058.2292815077728, mape loss: 8281.678380204488
##on valid data## rmse loss: 1574.1892613002233, mae loss: 1008.175094309921, mape loss: 1221.1095235062382
##on test data## rmse loss: 1764.5212467149418, mae loss: 1122.6448156879676, mape loss: 670.0167767099432

2024-10-30 15:27:40.224 | INFO     | __main__:main:190 - =====Epoch 4=====

##on train data## total loss: 0.048703328958951256, pred loss: 0.04323772181311225, regression loss: 0.005465607145839007 
##on train data## rmse loss: 1970.5969118999346, mae loss: 1024.759501268416, mape loss: 5951.564373162949
##on valid data## rmse loss: 1547.6869495053088, mae loss: 959.5633331063171, mape loss: 1100.4621485830735
##on test data## rmse loss: 1736.0954905624094, mae loss: 1071.0996931510542, mape loss: 673.8698906304753

2024-10-30 15:34:01.447 | INFO     | __main__:main:190 - =====Epoch 5=====

##on train data## total loss: 0.047351447757815725, pred loss: 0.04230923549327373, regression loss: 0.005042212264541995 
##on train data## rmse loss: 1901.6132187431838, mae loss: 977.8388561306871, mape loss: 2160.5160004104755
##on valid data## rmse loss: 1545.00674638785, mae loss: 929.7261056789561, mape loss: 444.98465506496575
##on test data## rmse loss: 1758.147117349632, mae loss: 1055.7017798110785, mape loss: 329.7316172580922

2024-10-30 15:40:07.013 | INFO     | __main__:main:190 - =====Epoch 6=====

##on train data## total loss: 0.046387000119037035, pred loss: 0.041642472504648184, regression loss: 0.004744527614388856 
##on train data## rmse loss: 1992.6126669481926, mae loss: 1145.7102148762815, mape loss: 1604.2862809475907
##on valid data## rmse loss: 1695.513215996584, mae loss: 1091.243453213607, mape loss: 639.5656172603253
##on test data## rmse loss: 1859.729311438601, mae loss: 1194.8094101835861, mape loss: 470.3836737797527

2024-10-30 15:46:15.509 | INFO     | __main__:main:190 - =====Epoch 7=====

##on train data## total loss: 0.04584392304898613, pred loss: 0.04118198729953421, regression loss: 0.004661935749451918 
##on train data## rmse loss: 1946.5040801382306, mae loss: 1167.0171903038993, mape loss: 8250.99623443814
##on valid data## rmse loss: 1616.3583353992594, mae loss: 1085.9787816817236, mape loss: 1507.5726488267132
##on test data## rmse loss: 1800.1908905147125, mae loss: 1195.0890831671165, mape loss: 959.9795054054629

2024-10-30 15:52:23.625 | INFO     | __main__:main:190 - =====Epoch 8=====

##on train data## total loss: 0.04522828251208524, pred loss: 0.04060792411196809, regression loss: 0.0046203584001171475 
##on train data## rmse loss: 1977.5719436800418, mae loss: 1041.540918650361, mape loss: 5201.522938067538
##on valid data## rmse loss: 1604.176856081458, mae loss: 1026.5502699921951, mape loss: 790.8150880148052
##on test data## rmse loss: 1803.370245384894, mae loss: 1143.2126892561157, mape loss: 438.07528711654044

2024-10-30 15:58:33.053 | INFO     | __main__:main:190 - =====Epoch 9=====

##on train data## total loss: 0.044937444197517454, pred loss: 0.04041755574531995, regression loss: 0.004519888452197506 
##on train data## rmse loss: 1890.8091039512362, mae loss: 1007.8434298365249, mape loss: 3374.065951216342
##on valid data## rmse loss: 1575.7735876134925, mae loss: 966.2722984520165, mape loss: 473.75436287128787
##on test data## rmse loss: 1792.1114470139435, mae loss: 1102.7227691296905, mape loss: 209.25843608655524

2024-10-30 16:04:36.482 | INFO     | __main__:main:190 - =====Epoch 10=====

##on train data## total loss: 0.044131737217918125, pred loss: 0.03969115872624677, regression loss: 0.004440578491671359 
##on train data## rmse loss: 1841.6739817004518, mae loss: 949.5920964933289, mape loss: 3340.3374407118954
##on valid data## rmse loss: 1484.0646953803691, mae loss: 904.6327199457235, mape loss: 566.7646526024608
##on test data## rmse loss: 1684.325561405609, mae loss: 1023.5846391479021, mape loss: 338.8938893855308

2024-10-30 16:10:54.665 | INFO     | __main__:main:190 - =====Epoch 11=====

##on train data## total loss: 0.04342209723090214, pred loss: 0.03920029840526067, regression loss: 0.00422179882564147 
##on train data## rmse loss: 1962.6436732723023, mae loss: 1097.0003883632912, mape loss: 1744.9514285486362
##on valid data## rmse loss: 1608.2931498523844, mae loss: 1019.7471088424153, mape loss: 496.05073471442154
##on test data## rmse loss: 1768.5397624012126, mae loss: 1114.3200377239684, mape loss: 426.332335312164

2024-10-30 16:17:11.737 | INFO     | __main__:main:190 - =====Epoch 12=====

##on train data## total loss: 0.043504707813369306, pred loss: 0.03939701389373773, regression loss: 0.004107693919631579 
##on train data## rmse loss: 1853.7110543420472, mae loss: 936.2723869285003, mape loss: 1073.543046777926
##on valid data## rmse loss: 1469.2586486109435, mae loss: 881.5816773521394, mape loss: 260.8590859473902
##on test data## rmse loss: 1676.3235166100462, mae loss: 1001.1523038061429, mape loss: 193.64382231672758

2024-10-30 16:23:23.834 | INFO     | __main__:main:190 - =====Epoch 13=====

##on train data## total loss: 0.04287121150474806, pred loss: 0.03883423671862973, regression loss: 0.00403697478611833 
##on train data## rmse loss: 1841.6758705565167, mae loss: 955.4423606214184, mape loss: 2704.5592739686444
##on valid data## rmse loss: 1481.020517238779, mae loss: 900.9642222636455, mape loss: 582.1411681796593
##on test data## rmse loss: 1687.0574775607429, mae loss: 1018.8315618802221, mape loss: 410.2387769974797

2024-10-30 16:29:28.003 | INFO     | __main__:main:190 - =====Epoch 14=====

##on train data## total loss: 0.04317452471250039, pred loss: 0.03904121679939811, regression loss: 0.0041333079131022875 
##on train data## rmse loss: 1850.8158310246347, mae loss: 933.5238773132944, mape loss: 1096.8955323213552
##on valid data## rmse loss: 1513.1636896906673, mae loss: 913.0347931615174, mape loss: 241.48528816962335
##on test data## rmse loss: 1753.9092129151334, mae loss: 1052.840418399531, mape loss: 164.9216048793443

2024-10-30 16:35:36.710 | INFO     | __main__:main:190 - =====Epoch 15=====

##on train data## total loss: 0.042622935414541194, pred loss: 0.03845078274531575, regression loss: 0.0041721526692254434 
##on train data## rmse loss: 1866.910856372814, mae loss: 1048.4582794111998, mape loss: 4910.901087590583
##on valid data## rmse loss: 1548.786245574362, mae loss: 997.2198997703758, mape loss: 1142.8624378783363
##on test data## rmse loss: 1734.4124729937107, mae loss: 1104.7721512842363, mape loss: 853.3158424508157

2024-10-30 16:41:44.802 | INFO     | __main__:main:190 - =====Epoch 16=====

##on train data## total loss: 0.04218870699748416, pred loss: 0.038226956480901735, regression loss: 0.0039617505165824235 
##on train data## rmse loss: 1884.4717362302208, mae loss: 1015.2225961055852, mape loss: 816.8415182775955
##on valid data## rmse loss: 1546.7129974954378, mae loss: 950.3678848679001, mape loss: 225.34209100896328
##on test data## rmse loss: 1717.491311091714, mae loss: 1053.5017676629616, mape loss: 226.6234314177027

