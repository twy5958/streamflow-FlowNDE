2024-11-07 09:53:48.156 | INFO     | __main__:main:139 - {'remote': False, 'device': 0, 'epochs': 200, 'seed': 42, 'batch_size': 8, 'filename': 'changjiang', 'train_ratio': 0.6, 'valid_ratio': 0.2, 'his_length': 12, 'pred_length': 12, 'num_layers': 1, 'lr': 0.0001, 'step_size': 1, 'hidden_dim': 64, 'back': 3, 'thres': 0.005, 'station': 'train', 'log': 'FALSE'}
2024-11-07 09:59:43.501 | INFO     | __main__:main:192 - =====Epoch 1=====

##on train data## total loss: 0.2842822392390767, pred loss: 0.13360841329999004, regression loss: 0.15067382593908665 
##on train data## rmse loss: 2758.6729548885132, mae loss: 1445.2568816364114, mape loss: 4936.244369324694
##on valid data## rmse loss: 2225.659038367638, mae loss: 1386.679012122521, mape loss: 942.5403574338326
##on test data## rmse loss: 2424.5673443134015, mae loss: 1514.0776003324067, mape loss: 365.0492870119902

2024-11-07 10:04:42.172 | INFO     | __main__:main:192 - =====Epoch 2=====

##on train data## total loss: 0.0986494672683252, pred loss: 0.06318567470448838, regression loss: 0.03546379256383681 
##on train data## rmse loss: 2346.0266705043423, mae loss: 1219.3520964027057, mape loss: 2840.455578517188
##on valid data## rmse loss: 1885.0273794320913, mae loss: 1166.66535550631, mape loss: 446.52426689863205
##on test data## rmse loss: 2116.0993591308593, mae loss: 1307.7286569448618, mape loss: 252.31228372225394

2024-11-07 10:09:40.624 | INFO     | __main__:main:192 - =====Epoch 3=====

##on train data## total loss: 0.05821152743150664, pred loss: 0.04719144722085144, regression loss: 0.011020080210655208 
##on train data## rmse loss: 2113.0336037263046, mae loss: 1152.6230055910682, mape loss: 3323.8722307276603
##on valid data## rmse loss: 1680.630324613131, mae loss: 1065.9936795748197, mape loss: 603.2776854359187
##on test data## rmse loss: 1885.0416170560397, mae loss: 1195.0145251934346, mape loss: 541.4316015060132

2024-11-07 10:14:38.810 | INFO     | __main__:main:192 - =====Epoch 4=====

##on train data## total loss: 0.05002452435473046, pred loss: 0.04324117690625572, regression loss: 0.006783347448474742 
##on train data## rmse loss: 2042.036497784145, mae loss: 1023.6989289104636, mape loss: 2019.4735666216932
##on valid data## rmse loss: 1587.2001359205979, mae loss: 966.258983201247, mape loss: 428.0595340980933
##on test data## rmse loss: 1805.992839402419, mae loss: 1096.5916856032152, mape loss: 273.43850523233414

2024-11-07 10:19:36.722 | INFO     | __main__:main:192 - =====Epoch 5=====

##on train data## total loss: 0.04776786950293947, pred loss: 0.041944769153496736, regression loss: 0.00582310034944274 
##on train data## rmse loss: 1999.4380120601752, mae loss: 989.7235912962009, mape loss: 1259.5079576606072
##on valid data## rmse loss: 1534.306983595628, mae loss: 927.7163675161509, mape loss: 359.10762848762363
##on test data## rmse loss: 1743.7189955491285, mae loss: 1053.5383634127104, mape loss: 307.5864166135971

2024-11-07 10:24:37.076 | INFO     | __main__:main:192 - =====Epoch 6=====

##on train data## total loss: 0.046159739296429504, pred loss: 0.04101286185042564, regression loss: 0.005146877446003863 
##on train data## rmse loss: 2000.562065318151, mae loss: 1007.4030679615621, mape loss: 1582.0821135177225
##on valid data## rmse loss: 1549.5261380709135, mae loss: 946.8279869666467, mape loss: 658.8169864163949
##on test data## rmse loss: 1735.2870077279897, mae loss: 1060.2949444110577, mape loss: 499.1936003359464

2024-11-07 10:29:39.329 | INFO     | __main__:main:192 - =====Epoch 7=====

##on train data## total loss: 0.044564530261683506, pred loss: 0.03988950006379557, regression loss: 0.0046750301978879414 
##on train data## rmse loss: 2018.3788915334014, mae loss: 1052.279820321175, mape loss: 1012.855866687552
##on valid data## rmse loss: 1610.758165564904, mae loss: 995.8782174917368, mape loss: 515.907007089028
##on test data## rmse loss: 1786.629735623873, mae loss: 1103.6423128568208, mape loss: 323.6036165287861

2024-11-07 10:33:26.107 | INFO     | __main__:main:192 - =====Epoch 8=====

##on train data## total loss: 0.04414182593502331, pred loss: 0.03955647739888166, regression loss: 0.004585348536141647 
##on train data## rmse loss: 1978.7613042066546, mae loss: 968.9580177268401, mape loss: 1746.5099615494007
##on valid data## rmse loss: 1521.7699540358324, mae loss: 915.7148525531476, mape loss: 386.40418582237686
##on test data## rmse loss: 1714.1469358004056, mae loss: 1034.434986760066, mape loss: 338.7768211502295

2024-11-07 10:37:07.691 | INFO     | __main__:main:192 - =====Epoch 9=====

##on train data## total loss: 0.04314995854785713, pred loss: 0.03882017741225031, regression loss: 0.0043297811356068205 
##on train data## rmse loss: 1959.7844258419752, mae loss: 1018.6399778569411, mape loss: 1968.3823870220765
##on valid data## rmse loss: 1582.7498021052434, mae loss: 976.4681243896484, mape loss: 364.14115716631596
##on test data## rmse loss: 1755.150095308744, mae loss: 1084.6971390944261, mape loss: 272.8764198605831

2024-11-07 10:40:48.691 | INFO     | __main__:main:192 - =====Epoch 10=====

##on train data## total loss: 0.042800622190310986, pred loss: 0.038651196738004184, regression loss: 0.0041494254523068005 
##on train data## rmse loss: 1928.9895155853426, mae loss: 954.6343777264435, mape loss: 2494.3198586100248
##on valid data## rmse loss: 1510.0850057748648, mae loss: 915.8390392596905, mape loss: 431.35304687114865
##on test data## rmse loss: 1685.2607313889723, mae loss: 1019.8279066819412, mape loss: 304.6103626489639

2024-11-07 10:44:27.845 | INFO     | __main__:main:192 - =====Epoch 11=====

##on train data## total loss: 0.0424110666271961, pred loss: 0.03834528921258891, regression loss: 0.004065777414607187 
##on train data## rmse loss: 1921.6053598471703, mae loss: 940.0845121586989, mape loss: 5378.544335634575
##on valid data## rmse loss: 1511.8555419921875, mae loss: 906.0641760019156, mape loss: 228.46974378594985
##on test data## rmse loss: 1691.3098637507512, mae loss: 1017.8781965989333, mape loss: 180.18368622431387

2024-11-07 10:48:07.750 | INFO     | __main__:main:192 - =====Epoch 12=====

##on train data## total loss: 0.04163605371504304, pred loss: 0.037719969667682214, regression loss: 0.003916084047360819 
##on train data## rmse loss: 1947.4609557795645, mae loss: 931.9696958900103, mape loss: 4670.308145199935
##on valid data## rmse loss: 1512.4713824932392, mae loss: 898.095869563176, mape loss: 183.2116469167746
##on test data## rmse loss: 1701.7173382098858, mae loss: 1014.6421070979192, mape loss: 197.998136729002

2024-11-07 10:51:46.889 | INFO     | __main__:main:192 - =====Epoch 13=====

##on train data## total loss: 0.041521478490431224, pred loss: 0.03769834742019766, regression loss: 0.00382313107023356 
##on train data## rmse loss: 1940.8033998750793, mae loss: 938.4607616753748, mape loss: 4570.297779574007
##on valid data## rmse loss: 1500.5529294527494, mae loss: 897.0044050950271, mape loss: 193.15822493571503
##on test data## rmse loss: 1685.7828376183143, mae loss: 1010.5486187274639, mape loss: 201.9924824283673

2024-11-07 10:55:26.257 | INFO     | __main__:main:192 - =====Epoch 14=====

##on train data## total loss: 0.04127781662551053, pred loss: 0.03749238894559469, regression loss: 0.003785427679915837 
##on train data## rmse loss: 1942.1778561354893, mae loss: 939.838075434496, mape loss: 4492.901888172033
##on valid data## rmse loss: 1526.0573237492488, mae loss: 907.9980521568885, mape loss: 198.0010845913337
##on test data## rmse loss: 1719.2665283203125, mae loss: 1022.9388939490685, mape loss: 191.931105026832

2024-11-07 10:59:04.997 | INFO     | __main__:main:192 - =====Epoch 15=====

##on train data## total loss: 0.04079073034510546, pred loss: 0.03706381729240222, regression loss: 0.00372691305270324 
##on train data## rmse loss: 1908.5257890575429, mae loss: 958.8609046742396, mape loss: 1278.6077793933414
##on valid data## rmse loss: 1498.5936678372896, mae loss: 922.7006791334886, mape loss: 620.5816183525783
##on test data## rmse loss: 1673.7307530329779, mae loss: 1033.4772071251502, mape loss: 469.0644640647448

2024-11-07 11:02:45.093 | INFO     | __main__:main:192 - =====Epoch 16=====

##on train data## total loss: 0.040575108748534455, pred loss: 0.0369102668089096, regression loss: 0.0036648419396248574 
##on train data## rmse loss: 1960.5892761540292, mae loss: 1060.8936902351186, mape loss: 1652.2036444717253
##on valid data## rmse loss: 1694.3850942758413, mae loss: 1053.693357027494, mape loss: 423.8088152844172
##on test data## rmse loss: 1832.5453204815203, mae loss: 1147.912653057392, mape loss: 345.13863928042923

2024-11-07 11:06:24.294 | INFO     | __main__:main:192 - =====Epoch 17=====

##on train data## total loss: 0.040296279412793554, pred loss: 0.0367155304234144, regression loss: 0.003580748989379156 
##on train data## rmse loss: 1887.8183187881702, mae loss: 932.731073602202, mape loss: 2342.5601016446417
##on valid data## rmse loss: 1509.40207425631, mae loss: 907.4139855018029, mape loss: 237.97095871888675
##on test data## rmse loss: 1682.3393247164213, mae loss: 1018.9722184401292, mape loss: 236.89127669884607

2024-11-07 11:10:03.035 | INFO     | __main__:main:192 - =====Epoch 18=====

##on train data## total loss: 0.03993459034068179, pred loss: 0.03636604080879045, regression loss: 0.0035685495318913464 
##on train data## rmse loss: 1960.8961409360625, mae loss: 972.7562038983185, mape loss: 5572.2151201086
##on valid data## rmse loss: 1583.0912189190203, mae loss: 951.9239490215595, mape loss: 339.59044566521277
##on test data## rmse loss: 1783.8425854022687, mae loss: 1075.1557936448316, mape loss: 179.33922885702208

2024-11-07 11:13:42.184 | INFO     | __main__:main:192 - =====Epoch 19=====

##on train data## total loss: 0.039635083783503035, pred loss: 0.03611096572495824, regression loss: 0.0035241180585447915 
##on train data## rmse loss: 1903.1475346754046, mae loss: 933.0780587753063, mape loss: 1198.8553304206296
##on valid data## rmse loss: 1486.7388735257662, mae loss: 894.7997103177585, mape loss: 373.25400933623314
##on test data## rmse loss: 1660.1069481482873, mae loss: 1002.3436516394981, mape loss: 324.72185865044594

