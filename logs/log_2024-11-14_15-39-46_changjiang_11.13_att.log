2024-11-14 15:39:46.706 | INFO     | __main__:main:139 - {'remote': False, 'device': 0, 'epochs': 200, 'seed': 42, 'batch_size': 4, 'filename': 'changjiang', 'train_ratio': 0.6, 'valid_ratio': 0.2, 'his_length': 12, 'pred_length': 12, 'num_layers': 1, 'lr': 0.0001, 'step_size': 1, 'hidden_dim': 64, 'back': 3, 'thres': 0.005, 'station': 'train', 'log': 'FALSE'}
2024-11-14 15:48:47.135 | INFO     | __main__:main:192 - =====Epoch 1=====

##on train data## total loss: 0.20362879282991084, pred loss: 0.11118689071559017, regression loss: 0.09244190211432068 
##on train data## rmse loss: 2567.297289736985, mae loss: 1387.4243293800935, mape loss: 2640.1455007228756
##on valid data## rmse loss: 2090.912519535963, mae loss: 1319.9055328958284, mape loss: 456.2452143913991
##on test data## rmse loss: 2302.4552434383672, mae loss: 1464.5628686853356, mape loss: 454.3459556277654

2024-11-14 15:57:44.367 | INFO     | __main__:main:192 - =====Epoch 2=====

##on train data## total loss: 0.08696703038291845, pred loss: 0.06050286811593563, regression loss: 0.026464162266982817 
##on train data## rmse loss: 2209.3907416484076, mae loss: 1188.5961649938283, mape loss: 3452.7696961224988
##on valid data## rmse loss: 1789.4463121568836, mae loss: 1117.778166192839, mape loss: 396.35523360898594
##on test data## rmse loss: 2022.54104366818, mae loss: 1269.8260681270172, mape loss: 406.135637931612

2024-11-14 16:06:36.607 | INFO     | __main__:main:192 - =====Epoch 3=====

##on train data## total loss: 0.059379033827657815, pred loss: 0.048329374297729724, regression loss: 0.011049659529928093 
##on train data## rmse loss: 2052.585113331751, mae loss: 1121.461942488772, mape loss: 4613.3888623663015
##on valid data## rmse loss: 1619.1928687371803, mae loss: 1035.6955939922555, mape loss: 915.8030974358666
##on test data## rmse loss: 1843.031497793308, mae loss: 1167.8988618003816, mape loss: 559.9864390365866

2024-11-14 16:15:30.262 | INFO     | __main__:main:192 - =====Epoch 4=====

##on train data## total loss: 0.05187381648852698, pred loss: 0.04497997759231827, regression loss: 0.006893838896208707 
##on train data## rmse loss: 2003.8714694492708, mae loss: 1081.1446450712717, mape loss: 8727.91831443455
##on valid data## rmse loss: 1617.4958193274538, mae loss: 1023.6154452290774, mape loss: 1018.6642752536015
##on test data## rmse loss: 1838.833279996305, mae loss: 1162.5117394288995, mape loss: 689.4824142736818

2024-11-14 16:24:22.589 | INFO     | __main__:main:192 - =====Epoch 5=====

##on train data## total loss: 0.049392618782886866, pred loss: 0.04345920944681981, regression loss: 0.005933409336067058 
##on train data## rmse loss: 1992.2461445609931, mae loss: 1089.9371188013686, mape loss: 2983.3501826536835
##on valid data## rmse loss: 1587.7192145977242, mae loss: 1007.7031039087009, mape loss: 653.116297675836
##on test data## rmse loss: 1790.4736143134276, mae loss: 1129.8302730133175, mape loss: 376.71848166173027

2024-11-14 16:33:06.059 | INFO     | __main__:main:192 - =====Epoch 6=====

##on train data## total loss: 0.048250620828517166, pred loss: 0.04297172780426649, regression loss: 0.005278893024250682 
##on train data## rmse loss: 1972.2641049302774, mae loss: 1045.853795240373, mape loss: 9328.490442911228
##on valid data## rmse loss: 1565.0398363975023, mae loss: 990.831719122338, mape loss: 1098.3656354852624
##on test data## rmse loss: 1790.7819213867188, mae loss: 1130.863835574117, mape loss: 714.2628905280677

2024-11-14 16:41:47.909 | INFO     | __main__:main:192 - =====Epoch 7=====

##on train data## total loss: 0.04721714360793097, pred loss: 0.04232837863670228, regression loss: 0.004888764971228692 
##on train data## rmse loss: 1979.15531255267, mae loss: 1117.7222452696205, mape loss: 3429.6810944484273
##on valid data## rmse loss: 1597.962740864993, mae loss: 1036.4891300864201, mape loss: 808.2331708384297
##on test data## rmse loss: 1790.852499825614, mae loss: 1157.0407382567416, mape loss: 398.1188741544959

2024-11-14 16:50:35.416 | INFO     | __main__:main:192 - =====Epoch 8=====

##on train data## total loss: 0.04609839063076312, pred loss: 0.04166141772293486, regression loss: 0.004436972907828261 
##on train data## rmse loss: 1944.1209642826602, mae loss: 1062.9095775391245, mape loss: 2399.6234628603543
##on valid data## rmse loss: 1561.969400884562, mae loss: 984.9392634800503, mape loss: 591.3386958216148
##on test data## rmse loss: 1766.1479230608259, mae loss: 1115.0546493235702, mape loss: 344.63294854955785

2024-11-14 16:59:15.761 | INFO     | __main__:main:192 - =====Epoch 9=====

##on train data## total loss: 0.04491987445676548, pred loss: 0.04076784188231069, regression loss: 0.0041520325744547944 
##on train data## rmse loss: 1918.696672468621, mae loss: 999.312939600291, mape loss: 7074.756431171131
##on valid data## rmse loss: 1530.9251757294055, mae loss: 940.305533155051, mape loss: 748.3056088902315
##on test data## rmse loss: 1739.1516492688977, mae loss: 1075.8650591051257, mape loss: 603.9197461140202

2024-11-14 17:07:54.153 | INFO     | __main__:main:192 - =====Epoch 10=====

##on train data## total loss: 0.044374541122747614, pred loss: 0.04044284254540323, regression loss: 0.003931698577344384 
##on train data## rmse loss: 1900.0324449878053, mae loss: 967.2531859693188, mape loss: 5005.53628196798
##on valid data## rmse loss: 1516.321138065294, mae loss: 917.2451819931679, mape loss: 433.4282306285438
##on test data## rmse loss: 1704.843424086405, mae loss: 1029.7234439923495, mape loss: 321.47208661646454

2024-11-14 17:16:29.898 | INFO     | __main__:main:192 - =====Epoch 11=====

##on train data## total loss: 0.043898115755380294, pred loss: 0.04009317281005342, regression loss: 0.003804942945326882 
##on train data## rmse loss: 1876.484239994572, mae loss: 979.8295035580088, mape loss: 2000.1263400927412
##on valid data## rmse loss: 1503.1311125884185, mae loss: 918.7569980105839, mape loss: 301.72237859729637
##on test data## rmse loss: 1680.8433010734645, mae loss: 1032.9772088481652, mape loss: 224.63088236375205

2024-11-14 17:25:05.880 | INFO     | __main__:main:192 - =====Epoch 12=====

##on train data## total loss: 0.043093222139496595, pred loss: 0.039460387317708845, regression loss: 0.0036328348217877443 
##on train data## rmse loss: 1917.1865560463843, mae loss: 1002.4773557633918, mape loss: 7911.171999097173
##on valid data## rmse loss: 1550.0629206476985, mae loss: 958.3008190729444, mape loss: 805.1326346788627
##on test data## rmse loss: 1743.7527393944936, mae loss: 1071.9603900688496, mape loss: 510.5015307895005

2024-11-14 17:33:37.372 | INFO     | __main__:main:192 - =====Epoch 13=====

##on train data## total loss: 0.042781188259986204, pred loss: 0.039228004507325574, regression loss: 0.0035531837526606314 
##on train data## rmse loss: 1933.0593356989361, mae loss: 1034.2612726821512, mape loss: 4244.509717557334
##on valid data## rmse loss: 1625.8225560722203, mae loss: 1000.6990758829595, mape loss: 393.8002742395438
##on test data## rmse loss: 1799.7841809836134, mae loss: 1114.1234034240015, mape loss: 338.2159769189864

2024-11-14 17:42:10.006 | INFO     | __main__:main:192 - =====Epoch 14=====

##on train data## total loss: 0.042299356054057255, pred loss: 0.03881051965415886, regression loss: 0.0034888363998983973 
##on train data## rmse loss: 1848.6358084896494, mae loss: 955.3826057511537, mape loss: 1490.2331551811114
##on valid data## rmse loss: 1492.131234894388, mae loss: 905.7771186975899, mape loss: 385.14502109477877
##on test data## rmse loss: 1668.544183915186, mae loss: 1019.0191908435012, mape loss: 221.27422534475915

2024-11-14 17:50:43.440 | INFO     | __main__:main:192 - =====Epoch 15=====

##on train data## total loss: 0.04185717716310197, pred loss: 0.038451227546192505, regression loss: 0.0034059496169094633 
##on train data## rmse loss: 1918.926619553929, mae loss: 1079.190180550977, mape loss: 2690.242436709743
##on valid data## rmse loss: 1600.06800659651, mae loss: 1027.3788785603056, mape loss: 842.629204316489
##on test data## rmse loss: 1760.3384745829815, mae loss: 1128.6837265427048, mape loss: 458.20504118576935

2024-11-14 17:59:14.495 | INFO     | __main__:main:192 - =====Epoch 16=====

##on train data## total loss: 0.041575597543895795, pred loss: 0.03815805168348473, regression loss: 0.0034175458604110602 
##on train data## rmse loss: 1887.1986248190633, mae loss: 955.1235894914811, mape loss: 4725.6584675557115
##on valid data## rmse loss: 1516.803177645768, mae loss: 915.5161906356517, mape loss: 518.1134576502914
##on test data## rmse loss: 1708.8478957953141, mae loss: 1025.0312563627383, mape loss: 364.45606001670757

2024-11-14 18:07:47.773 | INFO     | __main__:main:192 - =====Epoch 17=====

##on train data## total loss: 0.041292329050829815, pred loss: 0.037943083957686544, regression loss: 0.0033492450931432733 
##on train data## rmse loss: 1839.025515328809, mae loss: 978.9473406796528, mape loss: 1397.5191941342982
##on valid data## rmse loss: 1500.8886891957875, mae loss: 930.9264951138883, mape loss: 462.16745455407727
##on test data## rmse loss: 1672.0060773577009, mae loss: 1039.3384709302984, mape loss: 257.09854081905945

2024-11-14 18:16:23.049 | INFO     | __main__:main:192 - =====Epoch 18=====

##on train data## total loss: 0.040613741961693116, pred loss: 0.037335046871394204, regression loss: 0.003278695090298912 
##on train data## rmse loss: 1818.513266393981, mae loss: 921.1573691005029, mape loss: 1193.2433592864704
##on valid data## rmse loss: 1479.1467950887202, mae loss: 887.597464130652, mape loss: 357.9608827714294
##on test data## rmse loss: 1676.5501460366268, mae loss: 1010.3786336537954, mape loss: 249.00649017924047

2024-11-14 18:24:59.401 | INFO     | __main__:main:192 - =====Epoch 19=====

##on train data## total loss: 0.04052695154914453, pred loss: 0.037260520034897354, regression loss: 0.0032664315142471706 
##on train data## rmse loss: 1912.5611720980726, mae loss: 1007.0740512131434, mape loss: 6656.924899221223
##on valid data## rmse loss: 1590.8244460411513, mae loss: 977.1024069767661, mape loss: 745.9899428440797
##on test data## rmse loss: 1765.876862632722, mae loss: 1085.8440762670805, mape loss: 383.66659136352393

2024-11-14 18:33:49.873 | INFO     | __main__:main:192 - =====Epoch 20=====

##on train data## total loss: 0.040433884098674384, pred loss: 0.03720576672812829, regression loss: 0.0032281173705460938 
##on train data## rmse loss: 1809.2253153844533, mae loss: 910.7089142968812, mape loss: 1166.8596822409158
##on valid data## rmse loss: 1468.422820102294, mae loss: 873.2819635693171, mape loss: 262.4287844682292
##on test data## rmse loss: 1649.1311270813223, mae loss: 984.2770875908693, mape loss: 176.98019700390952

2024-11-14 18:42:25.174 | INFO     | __main__:main:192 - =====Epoch 21=====

##on train data## total loss: 0.04012177437753653, pred loss: 0.036891462842121366, regression loss: 0.003230311535415166 
##on train data## rmse loss: 1870.563896605206, mae loss: 1073.8777963086434, mape loss: 4771.4151774187985
##on valid data## rmse loss: 1580.8319341593267, mae loss: 1034.761578180615, mape loss: 1050.0691852514349
##on test data## rmse loss: 1740.201149605416, mae loss: 1134.218844380618, mape loss: 667.2464370382338

2024-11-14 18:51:08.924 | INFO     | __main__:main:192 - =====Epoch 22=====

##on train data## total loss: 0.03989425186436567, pred loss: 0.03669180317677639, regression loss: 0.0032024486875892816 
##on train data## rmse loss: 1804.1746293276094, mae loss: 917.0024647398044, mape loss: 2814.1321538025654
##on valid data## rmse loss: 1496.1998083637488, mae loss: 895.9049422805374, mape loss: 307.90277819030536
##on test data## rmse loss: 1680.0987249543768, mae loss: 1009.9841882418482, mape loss: 239.40905371112714

