2024-11-06 21:14:35.046 | INFO     | __main__:main:139 - {'remote': False, 'device': 0, 'epochs': 200, 'seed': 42, 'batch_size': 16, 'filename': 'changjiang', 'train_ratio': 0.6, 'valid_ratio': 0.2, 'his_length': 12, 'pred_length': 12, 'num_layers': 1, 'lr': 0.0001, 'step_size': 1, 'hidden_dim': 64, 'back': 3, 'thres': 0.005, 'station': 'train', 'log': 'FALSE'}
2024-11-06 21:17:15.016 | INFO     | __main__:main:192 - =====Epoch 1=====

##on train data## total loss: 0.42331115345513154, pred loss: 0.1849113206572944, regression loss: 0.23839983279783714 
##on train data## rmse loss: 3047.59654894214, mae loss: 1682.15307369329, mape loss: 5340.188457033961
##on valid data## rmse loss: 2530.721950120192, mae loss: 1613.9952965369591, mape loss: 1210.4553022292944
##on test data## rmse loss: 2699.7209754356973, mae loss: 1739.2754544771635, mape loss: 382.06327750132635

2024-11-06 21:19:52.363 | INFO     | __main__:main:192 - =====Epoch 2=====

##on train data## total loss: 0.1304758647976793, pred loss: 0.07420152467368218, regression loss: 0.056274340123997124 
##on train data## rmse loss: 2730.078589115046, mae loss: 1432.010850935418, mape loss: 6124.408124909183
##on valid data## rmse loss: 2225.534249173678, mae loss: 1363.0262915978064, mape loss: 932.361058134299
##on test data## rmse loss: 2403.265418419471, mae loss: 1484.8269362229566, mape loss: 413.14012055213635

2024-11-06 21:22:27.709 | INFO     | __main__:main:192 - =====Epoch 3=====

##on train data## total loss: 0.0994406624834247, pred loss: 0.06232066974422048, regression loss: 0.03711999273920422 
##on train data## rmse loss: 2373.090982659819, mae loss: 1230.7225481217283, mape loss: 3726.220703125
##on valid data## rmse loss: 1891.7601130558894, mae loss: 1158.7392451359676, mape loss: 507.5626252706234
##on test data## rmse loss: 2087.354094050481, mae loss: 1285.5219210111177, mape loss: 290.3510416012544

2024-11-06 21:25:04.701 | INFO     | __main__:main:192 - =====Epoch 4=====

##on train data## total loss: 0.06717257488159661, pred loss: 0.048946210549586464, regression loss: 0.018226364332010147 
##on train data## rmse loss: 2185.844844914935, mae loss: 1119.1440485455664, mape loss: 2279.897905727328
##on valid data## rmse loss: 1692.5635070800781, mae loss: 1034.175913649339, mape loss: 699.1925046994136
##on test data## rmse loss: 1900.4045198880708, mae loss: 1162.9480891301082, mape loss: 241.64453345995682

2024-11-06 21:27:39.752 | INFO     | __main__:main:192 - =====Epoch 5=====

##on train data## total loss: 0.053225739925229915, pred loss: 0.04470773745886036, regression loss: 0.008518002466369553 
##on train data## rmse loss: 2109.61450938888, mae loss: 1065.3476327034423, mape loss: 2190.098814250249
##on valid data## rmse loss: 1637.1430133526142, mae loss: 985.546156663161, mape loss: 368.2074041549976
##on test data## rmse loss: 1833.6714608999398, mae loss: 1108.0215909517729, mape loss: 284.47161000508527

2024-11-06 21:30:14.618 | INFO     | __main__:main:192 - =====Epoch 6=====

##on train data## total loss: 0.04989630804600449, pred loss: 0.04283941995357234, regression loss: 0.007056888092432152 
##on train data## rmse loss: 2087.2624889702965, mae loss: 1054.850373398834, mape loss: 2218.791711511951
##on valid data## rmse loss: 1634.4379732572115, mae loss: 985.3399409367488, mape loss: 470.1398337345857
##on test data## rmse loss: 1817.3705730731672, mae loss: 1105.53614455003, mape loss: 484.1078794002533

2024-11-06 21:32:50.499 | INFO     | __main__:main:192 - =====Epoch 7=====

##on train data## total loss: 0.047646244950025216, pred loss: 0.04144902843781061, regression loss: 0.006197216512214601 
##on train data## rmse loss: 2091.2150073366115, mae loss: 1089.9972602340777, mape loss: 3429.0734623894473
##on valid data## rmse loss: 1662.7304020808294, mae loss: 1020.3436016376202, mape loss: 751.9165189449603
##on test data## rmse loss: 1832.79071091872, mae loss: 1132.0290771484374, mape loss: 539.3020498752594

2024-11-06 21:35:29.590 | INFO     | __main__:main:192 - =====Epoch 8=====

##on train data## total loss: 0.04660979212086818, pred loss: 0.04096487307859594, regression loss: 0.005644919042272238 
##on train data## rmse loss: 2067.772291774072, mae loss: 1004.658171832864, mape loss: 1751.0107057348725
##on valid data## rmse loss: 1627.1894094613883, mae loss: 959.850830078125, mape loss: 292.50182243493884
##on test data## rmse loss: 1816.3868182842548, mae loss: 1080.3201068584735, mape loss: 232.6863442475979

2024-11-06 21:38:04.814 | INFO     | __main__:main:192 - =====Epoch 9=====

##on train data## total loss: 0.04538902762785629, pred loss: 0.040190624151151946, regression loss: 0.005198403476704347 
##on train data## rmse loss: 2046.4864625882376, mae loss: 1057.8877699798738, mape loss: 1058.0978730003242
##on valid data## rmse loss: 1648.0732572115385, mae loss: 999.8199998121995, mape loss: 365.56339552769293
##on test data## rmse loss: 1821.2026907113882, mae loss: 1118.3998103215145, mape loss: 245.62559600059802

2024-11-06 21:40:42.620 | INFO     | __main__:main:192 - =====Epoch 10=====

##on train data## total loss: 0.04444137852412039, pred loss: 0.03961224830532115, regression loss: 0.0048291302187992305 
##on train data## rmse loss: 2017.404640159026, mae loss: 991.3220078521574, mape loss: 1272.5085905663252
##on valid data## rmse loss: 1557.7871915377104, mae loss: 927.9136075533353, mape loss: 356.96974497575025
##on test data## rmse loss: 1724.077903864934, mae loss: 1035.1837740384615, mape loss: 268.2076279933636

2024-11-06 21:43:20.359 | INFO     | __main__:main:192 - =====Epoch 11=====

##on train data## total loss: 0.04370485974693208, pred loss: 0.03916258624457012, regression loss: 0.004542273502361956 
##on train data## rmse loss: 2010.6459266933693, mae loss: 1008.655432996411, mape loss: 1781.1669818035841
##on valid data## rmse loss: 1595.416555081881, mae loss: 956.7407123272236, mape loss: 381.5100994935402
##on test data## rmse loss: 1750.859805063101, mae loss: 1061.8986708420973, mape loss: 277.62750643950244

2024-11-06 21:45:52.874 | INFO     | __main__:main:192 - =====Epoch 12=====

##on train data## total loss: 0.04299530960373618, pred loss: 0.0386512973227628, regression loss: 0.004344012280973384 
##on train data## rmse loss: 1994.8929629253253, mae loss: 990.0854628509676, mape loss: 1096.769128202787
##on valid data## rmse loss: 1562.575834773137, mae loss: 935.8166672926683, mape loss: 462.86391565432916
##on test data## rmse loss: 1721.8074143629808, mae loss: 1043.9918842022234, mape loss: 365.9134139922949

2024-11-06 21:48:27.855 | INFO     | __main__:main:192 - =====Epoch 13=====

##on train data## total loss: 0.042738200425345284, pred loss: 0.03848347507374654, regression loss: 0.004254725351598738 
##on train data## rmse loss: 1983.4238776967004, mae loss: 960.7802331604934, mape loss: 2874.016304276316
##on valid data## rmse loss: 1543.8913870004508, mae loss: 911.7345088078425, mape loss: 364.7869992714662
##on test data## rmse loss: 1703.7277555025541, mae loss: 1017.9912963867188, mape loss: 264.229593368677

2024-11-06 21:51:01.365 | INFO     | __main__:main:192 - =====Epoch 14=====

##on train data## total loss: 0.04264049110981413, pred loss: 0.03848680010039435, regression loss: 0.004153691009419785 
##on train data## rmse loss: 1978.3187860014475, mae loss: 959.1596713768045, mape loss: 2237.76101987374
##on valid data## rmse loss: 1544.2124849759616, mae loss: 915.4020188551683, mape loss: 364.8454458438433
##on test data## rmse loss: 1698.4108271672176, mae loss: 1019.6604454627404, mape loss: 270.74265003204346

2024-11-06 21:53:36.191 | INFO     | __main__:main:192 - =====Epoch 15=====

##on train data## total loss: 0.04221753056544035, pred loss: 0.03808852170976966, regression loss: 0.0041290088556706905 
##on train data## rmse loss: 1989.403211564582, mae loss: 951.5394795219305, mape loss: 1856.8217416402651
##on valid data## rmse loss: 1546.907054255559, mae loss: 907.7639981783353, mape loss: 354.40196404090295
##on test data## rmse loss: 1708.976134314904, mae loss: 1017.3385446401743, mape loss: 241.78881168365479

2024-11-06 21:56:10.425 | INFO     | __main__:main:192 - =====Epoch 16=====

##on train data## total loss: 0.041644907003353694, pred loss: 0.03765089056858802, regression loss: 0.003994016434765672 
##on train data## rmse loss: 1993.3926394699795, mae loss: 1063.5506539126943, mape loss: 1549.3988821954292
##on valid data## rmse loss: 1647.1149291992188, mae loss: 1022.9389620267428, mape loss: 689.0849237258618
##on test data## rmse loss: 1779.557240647536, mae loss: 1114.9974989670973, mape loss: 494.8873126048308

2024-11-06 21:58:44.741 | INFO     | __main__:main:192 - =====Epoch 17=====

##on train data## total loss: 0.04106856105366939, pred loss: 0.03715855264941675, regression loss: 0.003910008404252644 
##on train data## rmse loss: 1987.0004250773318, mae loss: 948.3200435735248, mape loss: 2366.1768360186347
##on valid data## rmse loss: 1542.0249483548678, mae loss: 906.4244539701021, mape loss: 334.43741637926837
##on test data## rmse loss: 1698.7461360051082, mae loss: 1011.5720505934495, mape loss: 240.6914352453672

2024-11-06 22:01:17.789 | INFO     | __main__:main:192 - =====Epoch 18=====

##on train data## total loss: 0.04099178576113911, pred loss: 0.0371584123275881, regression loss: 0.003833373433551018 
##on train data## rmse loss: 1955.4163849341687, mae loss: 937.3908499315911, mape loss: 2578.2524786927374
##on valid data## rmse loss: 1551.5139526367188, mae loss: 903.7565889798678, mape loss: 337.32415694456836
##on test data## rmse loss: 1704.830850454477, mae loss: 1012.807717191256, mape loss: 255.7735472000562

2024-11-06 22:03:53.817 | INFO     | __main__:main:192 - =====Epoch 19=====

##on train data## total loss: 0.04099890646917112, pred loss: 0.0371639407641694, regression loss: 0.0038349657050017172 
##on train data## rmse loss: 1972.8687762730012, mae loss: 946.4323341640724, mape loss: 1253.994474525984
##on valid data## rmse loss: 1537.763780799279, mae loss: 905.0799799992488, mape loss: 386.93523310698
##on test data## rmse loss: 1694.702057823768, mae loss: 1012.8220116248498, mape loss: 323.2368859877953

2024-11-06 22:06:28.320 | INFO     | __main__:main:192 - =====Epoch 20=====

##on train data## total loss: 0.040792293350217, pred loss: 0.037040141635387665, regression loss: 0.0037521517148293403 
##on train data## rmse loss: 1941.935172298838, mae loss: 970.3164471466529, mape loss: 1169.4107226611393
##on valid data## rmse loss: 1570.3501272348258, mae loss: 937.6379263070913, mape loss: 342.5023812514085
##on test data## rmse loss: 1707.5955270620493, mae loss: 1034.9823134202225, mape loss: 258.47050873132855

