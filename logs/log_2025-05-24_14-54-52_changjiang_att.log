2025-05-24 14:54:52.461 | INFO     | __main__:main:138 - {'remote': False, 'device': 0, 'epochs': 200, 'seed': 42, 'batch_size': 4, 'filename': 'changjiang', 'train_ratio': 0.6, 'valid_ratio': 0.2, 'his_length': 12, 'pred_length': 12, 'num_layers': 1, 'lr': 0.001, 'step_size': 1, 'hidden_dim': 64, 'back': 3, 'thres': 0.005, 'station': 'train', 'log': 'FALSE'}
2025-05-24 15:03:38.280 | INFO     | __main__:main:191 - =====Epoch 1=====

##on train data## total loss: 0.08583790375106509, pred loss: 0.061640617634074614, regression loss: 0.024197286116990478 
##on train data## rmse loss: 2107.3481029374952, mae loss: 1251.6597519308177, mape loss: 7390.209589248078
##on valid data## rmse loss: 1724.924651039153, mae loss: 1158.700489530232, mape loss: 1308.2671764504496
##on test data## rmse loss: 1893.6486667942356, mae loss: 1265.6495191655104, mape loss: 759.9194560041759

2025-05-24 15:12:22.145 | INFO     | __main__:main:191 - =====Epoch 2=====

##on train data## total loss: 0.050383823427376406, pred loss: 0.04471605184975081, regression loss: 0.005667771577625594 
##on train data## rmse loss: 1966.7333900722756, mae loss: 1057.1005317184527, mape loss: 6739.881487345786
##on valid data## rmse loss: 1552.8161456133869, mae loss: 968.3875298813043, mape loss: 876.4736981005282
##on test data## rmse loss: 1766.3830492174304, mae loss: 1098.7392078532216, mape loss: 367.80562762703215

2025-05-24 15:21:07.113 | INFO     | __main__:main:191 - =====Epoch 3=====

##on train data## total loss: 0.04830998664593022, pred loss: 0.043094291196318184, regression loss: 0.005215695449612033 
##on train data## rmse loss: 1918.3128703548218, mae loss: 969.1068471918252, mape loss: 1347.9254090959953
##on valid data## rmse loss: 1483.4409972673218, mae loss: 902.1933362217023, mape loss: 380.90967104471787
##on test data## rmse loss: 1691.1436205536243, mae loss: 1021.523681640625, mape loss: 200.49216687449157

2025-05-24 15:29:46.968 | INFO     | __main__:main:191 - =====Epoch 4=====

##on train data## total loss: 0.047272983791902284, pred loss: 0.04214722106473974, regression loss: 0.005125762727162547 
##on train data## rmse loss: 1926.7410413093373, mae loss: 979.6701313347986, mape loss: 1792.250827964641
##on valid data## rmse loss: 1555.4515353169681, mae loss: 941.7002419136666, mape loss: 302.81748993171226
##on test data## rmse loss: 1756.2965390709837, mae loss: 1065.0013296355612, mape loss: 160.33863107670228

2025-05-24 15:38:29.191 | INFO     | __main__:main:191 - =====Epoch 5=====

##on train data## total loss: 0.04440945712288104, pred loss: 0.03998943840528467, regression loss: 0.004420018717596369 
##on train data## rmse loss: 1945.0972657954028, mae loss: 1082.9881342001977, mape loss: 1952.0757413833273
##on valid data## rmse loss: 1624.980400527306, mae loss: 1030.2401941954859, mape loss: 240.10459892883264
##on test data## rmse loss: 1774.2615715822199, mae loss: 1117.812902148626, mape loss: 238.25736813333504

2025-05-24 15:47:12.850 | INFO     | __main__:main:191 - =====Epoch 6=====

##on train data## total loss: 0.044482086511679834, pred loss: 0.039820854940208955, regression loss: 0.004661231571470883 
##on train data## rmse loss: 1844.2090912252513, mae loss: 967.6683156938117, mape loss: 7317.201507866836
##on valid data## rmse loss: 1522.8993822488085, mae loss: 950.3016526505754, mape loss: 898.0689279821388
##on test data## rmse loss: 1707.2730318165193, mae loss: 1060.7796158367141, mape loss: 407.95533365954765

2025-05-24 15:55:54.367 | INFO     | __main__:main:191 - =====Epoch 7=====

##on train data## total loss: 0.04377999287887552, pred loss: 0.03916589771887893, regression loss: 0.0046140951599965944 
##on train data## rmse loss: 1835.6146914486958, mae loss: 993.9088494935012, mape loss: 5745.491539853328
##on valid data## rmse loss: 1502.7789079231645, mae loss: 938.9998295021794, mape loss: 953.3387936680473
##on test data## rmse loss: 1673.929045334746, mae loss: 1041.9554219485249, mape loss: 662.206240372308

2025-05-24 16:04:39.698 | INFO     | __main__:main:191 - =====Epoch 8=====

##on train data## total loss: 0.04182424746024739, pred loss: 0.037663961740386165, regression loss: 0.004160285719861229 
##on train data## rmse loss: 1862.1274824578145, mae loss: 1020.7554588124232, mape loss: 2363.5530010924726
##on valid data## rmse loss: 1563.4748644736742, mae loss: 971.2894439108123, mape loss: 467.06843309996214
##on test data## rmse loss: 1704.0618359186474, mae loss: 1056.676609937749, mape loss: 378.7274762527823

2025-05-24 16:13:20.764 | INFO     | __main__:main:191 - =====Epoch 9=====

##on train data## total loss: 0.04095201348610515, pred loss: 0.036924812419613026, regression loss: 0.004027201066492125 
##on train data## rmse loss: 1816.5809399367588, mae loss: 934.0334993159105, mape loss: 2432.5733432423344
##on valid data## rmse loss: 1532.7682126903167, mae loss: 927.7804236099066, mape loss: 424.23428116963174
##on test data## rmse loss: 1753.879937956232, mae loss: 1057.9843937347293, mape loss: 297.99193379731713

2025-05-24 16:22:00.567 | INFO     | __main__:main:191 - =====Epoch 10=====

##on train data## total loss: 0.04063850288636283, pred loss: 0.03658513993109478, regression loss: 0.004053362955268045 
##on train data## rmse loss: 1800.1757891892178, mae loss: 928.9178124055039, mape loss: 3579.892120907452
##on valid data## rmse loss: 1535.237666185298, mae loss: 928.4016912158392, mape loss: 450.9847968011289
##on test data## rmse loss: 1717.9632894744284, mae loss: 1036.5429222077476, mape loss: 227.72839289719533

2025-05-24 16:30:42.626 | INFO     | __main__:main:191 - =====Epoch 11=====

##on train data## total loss: 0.03998699135396412, pred loss: 0.03602782231994147, regression loss: 0.003959169034022651 
##on train data## rmse loss: 1795.668256265863, mae loss: 983.2985624903955, mape loss: 1609.3330019962061
##on valid data## rmse loss: 1597.9115063288036, mae loss: 1001.2091201723313, mape loss: 531.3111263812739
##on test data## rmse loss: 1754.316221377104, mae loss: 1087.0549059540149, mape loss: 343.50815343465587

2025-05-24 16:39:23.471 | INFO     | __main__:main:191 - =====Epoch 12=====

##on train data## total loss: 0.03946788391532131, pred loss: 0.035550884311832016, regression loss: 0.003916999603489291 
##on train data## rmse loss: 1788.7801514059154, mae loss: 908.0753857375402, mape loss: 4384.742685823422
##on valid data## rmse loss: 1513.576349972758, mae loss: 919.1735028005475, mape loss: 574.6358076865608
##on test data## rmse loss: 1715.8848305484962, mae loss: 1039.0500547195493, mape loss: 339.5261972624823

