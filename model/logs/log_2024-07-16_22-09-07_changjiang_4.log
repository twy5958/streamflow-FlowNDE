2024-07-16 22:09:07.663 | INFO     | __main__:main:137 - {'remote': False, 'device': 0, 'epochs': 200, 'seed': 42, 'batch_size': 4, 'filename': 'changjiang', 'train_ratio': 0.6, 'valid_ratio': 0.2, 'his_length': 12, 'pred_length': 12, 'num_layers': 1, 'lr': 0.001, 'step_size': 1, 'hidden_dim': 64, 'back': 3, 'thres': 0.005, 'station': 'train', 'log': 'FALSE'}
2024-07-16 22:15:01.274 | INFO     | __main__:main:190 - =====Epoch 1=====

##on train data## total loss: 0.09448171123155502, pred loss: 0.06567175914905729, regression loss: 0.028809952082497724 
##on train data## rmse loss: 2120.247197107615, mae loss: 1236.9347119791253, mape loss: 8323.792720204077
##on valid data## rmse loss: 1733.7490058810554, mae loss: 1144.3955953590657, mape loss: 1328.4084963292228
##on test data## rmse loss: 1934.2697416916778, mae loss: 1266.4904977216684, mape loss: 799.6512370450156

2024-07-16 22:22:32.896 | INFO     | __main__:main:190 - =====Epoch 2=====

##on train data## total loss: 0.053955345046422847, pred loss: 0.04643034763033809, regression loss: 0.0075249974160847555 
##on train data## rmse loss: 2060.3126360123533, mae loss: 1146.863489915877, mape loss: 2862.1289866602965
##on valid data## rmse loss: 1646.443530933277, mae loss: 1038.4920484623854, mape loss: 307.2527487708335
##on test data## rmse loss: 1861.3843187015489, mae loss: 1171.2487908440667, mape loss: 326.62312440775537

2024-07-16 22:31:05.267 | INFO     | __main__:main:190 - =====Epoch 3=====

##on train data## total loss: 0.05074610009518816, pred loss: 0.04475002939380566, regression loss: 0.005996070701382501 
##on train data## rmse loss: 2047.874013832983, mae loss: 1074.4225972751676, mape loss: 3193.0393964543864
##on valid data## rmse loss: 1649.2703836212747, mae loss: 1028.8366922503733, mape loss: 641.602587964544
##on test data## rmse loss: 1877.8112295732535, mae loss: 1160.324969553119, mape loss: 292.813484480022

2024-07-16 22:41:08.503 | INFO     | __main__:main:190 - =====Epoch 4=====

##on train data## total loss: 0.04871310692648096, pred loss: 0.04325592579587621, regression loss: 0.005457181130604745 
##on train data## rmse loss: 2102.8936113076766, mae loss: 1145.7352501341534, mape loss: 3377.464717354266
##on valid data## rmse loss: 1713.9437938086314, mae loss: 1120.0918039447092, mape loss: 684.8233090289311
##on test data## rmse loss: 1925.1659920593027, mae loss: 1249.3956550981088, mape loss: 313.7640939486073

2024-07-16 22:51:11.020 | INFO     | __main__:main:190 - =====Epoch 5=====

##on train data## total loss: 0.04808558720763215, pred loss: 0.042780988973833985, regression loss: 0.005304598233798166 
##on train data## rmse loss: 1915.5757892047088, mae loss: 1013.1189026808376, mape loss: 1539.2245648476073
##on valid data## rmse loss: 1516.9070024527177, mae loss: 928.1828311640323, mape loss: 274.4045792514293
##on test data## rmse loss: 1699.9578511006123, mae loss: 1034.9002577144668, mape loss: 220.2709723508496

2024-07-16 23:01:15.507 | INFO     | __main__:main:190 - =====Epoch 6=====

##on train data## total loss: 0.047234426492909064, pred loss: 0.04232864108690144, regression loss: 0.004905785406007624 
##on train data## rmse loss: 2026.6532000236705, mae loss: 1097.5166356043162, mape loss: 3368.3350235866715
##on valid data## rmse loss: 1666.0772482382285, mae loss: 1031.0470169833268, mape loss: 437.30110008859265
##on test data## rmse loss: 1840.947931709437, mae loss: 1141.6320949245144, mape loss: 438.51490350418567

2024-07-16 23:10:44.365 | INFO     | __main__:main:190 - =====Epoch 7=====

##on train data## total loss: 0.04657152800751037, pred loss: 0.04172467856621695, regression loss: 0.004846849441293421 
##on train data## rmse loss: 2000.3002516848182, mae loss: 1153.801752894058, mape loss: 1981.4893594361502
##on valid data## rmse loss: 1687.143062046596, mae loss: 1086.0656669940727, mape loss: 575.0891093524266
##on test data## rmse loss: 1856.3040686647864, mae loss: 1193.0420244725053, mape loss: 567.0838891654402

2024-07-16 23:16:53.666 | INFO     | __main__:main:190 - =====Epoch 8=====

##on train data## total loss: 0.04571417407345424, pred loss: 0.04119844546191882, regression loss: 0.0045157286115354136 
##on train data## rmse loss: 1890.3210166892425, mae loss: 989.5287115416551, mape loss: 1285.5096762479864
##on valid data## rmse loss: 1498.7247829363614, mae loss: 905.0811623238228, mape loss: 187.24630962352495
##on test data## rmse loss: 1680.1339211482339, mae loss: 1014.9316719084633, mape loss: 190.4761477671995

2024-07-16 23:22:56.536 | INFO     | __main__:main:190 - =====Epoch 9=====

##on train data## total loss: 0.044687890149842056, pred loss: 0.04032565998258072, regression loss: 0.0043622301672613375 
##on train data## rmse loss: 1866.7452638500233, mae loss: 984.1177255853179, mape loss: 2874.006876689831
##on valid data## rmse loss: 1508.7177694313314, mae loss: 935.2449195891273, mape loss: 625.6144185669174
##on test data## rmse loss: 1719.325411409945, mae loss: 1066.730852046068, mape loss: 599.9935793025153

2024-07-16 23:28:54.812 | INFO     | __main__:main:190 - =====Epoch 10=====

##on train data## total loss: 0.043932158667192356, pred loss: 0.03966656375250473, regression loss: 0.004265594914687625 
##on train data## rmse loss: 1859.8792785024884, mae loss: 947.6649763814083, mape loss: 1271.7670891755427
##on valid data## rmse loss: 1496.0393820508566, mae loss: 900.3919198172433, mape loss: 307.0920169065818
##on test data## rmse loss: 1707.8938683469323, mae loss: 1027.3536525417019, mape loss: 209.91842910704926

2024-07-16 23:34:39.187 | INFO     | __main__:main:190 - =====Epoch 11=====

##on train data## total loss: 0.04337741653118779, pred loss: 0.039268780552253524, regression loss: 0.004108635978934267 
##on train data## rmse loss: 1880.2109365705305, mae loss: 1030.7365849683733, mape loss: 3991.2432216145667
##on valid data## rmse loss: 1550.386580065871, mae loss: 966.4476159290917, mape loss: 824.7461130835375
##on test data## rmse loss: 1731.8801072757676, mae loss: 1076.7318751508205, mape loss: 645.6447910733204

2024-07-16 23:40:44.179 | INFO     | __main__:main:190 - =====Epoch 12=====

##on train data## total loss: 0.043346287363839955, pred loss: 0.03902976046800011, regression loss: 0.004316526895839849 
##on train data## rmse loss: 1923.4878920734232, mae loss: 992.3303142876795, mape loss: 2553.700391876365
##on valid data## rmse loss: 1572.6240016392298, mae loss: 975.5857852066806, mape loss: 536.6643792989171
##on test data## rmse loss: 1775.483845832265, mae loss: 1096.14565928102, mape loss: 325.4570984472179

2024-07-16 23:47:05.069 | INFO     | __main__:main:190 - =====Epoch 13=====

##on train data## total loss: 0.04261820413571721, pred loss: 0.038502685805041195, regression loss: 0.004115518330676016 
##on train data## rmse loss: 1884.7625412142215, mae loss: 975.2795458178834, mape loss: 3072.9756696234804
##on valid data## rmse loss: 1554.2497809568426, mae loss: 939.6130694532947, mape loss: 551.9643165199913
##on test data## rmse loss: 1741.7347528759576, mae loss: 1054.302784452107, mape loss: 197.21795475851155

2024-07-16 23:53:38.591 | INFO     | __main__:main:190 - =====Epoch 14=====

##on train data## total loss: 0.04326491361645849, pred loss: 0.03906517702491356, regression loss: 0.004199736591544934 
##on train data## rmse loss: 1863.3094314730106, mae loss: 989.7904355586483, mape loss: 5959.901059475647
##on valid data## rmse loss: 1546.5029686887292, mae loss: 956.8912790659311, mape loss: 883.770702393819
##on test data## rmse loss: 1751.9064142529107, mae loss: 1076.0188036001787, mape loss: 368.21820261855845

