2024-07-15 20:47:48.127 | INFO     | __main__:main:137 - {'remote': False, 'device': 0, 'epochs': 200, 'seed': 42, 'batch_size': 16, 'filename': 'changjiang', 'train_ratio': 0.6, 'valid_ratio': 0.2, 'his_length': 12, 'pred_length': 12, 'num_layers': 1, 'lr': 0.001, 'step_size': 1, 'hidden_dim': 64, 'back': 3, 'thres': 0.005, 'station': 'train', 'log': 'FALSE'}
2024-07-15 20:49:22.484 | INFO     | __main__:main:190 - =====Epoch 1=====

##on train data## total loss: 0.14348561193812923, pred loss: 0.08718385590656381, regression loss: 0.056301756031565404 
##on train data## rmse loss: 2337.63965339467, mae loss: 1281.9942946070946, mape loss: 5422.454534448343
##on valid data## rmse loss: 1867.1755314753607, mae loss: 1193.306138728215, mape loss: 1319.1792544951807
##on test data## rmse loss: 2062.3667170597955, mae loss: 1324.9291231595553, mape loss: 793.7205000107105

2024-07-15 20:50:49.664 | INFO     | __main__:main:190 - =====Epoch 2=====

##on train data## total loss: 0.061301817304364924, pred loss: 0.04934266826071715, regression loss: 0.011959149043647772 
##on train data## rmse loss: 2169.946738306036, mae loss: 1176.1374198797391, mape loss: 5085.0200155664825
##on valid data## rmse loss: 1727.5553124060998, mae loss: 1090.3359515850361, mape loss: 934.7992538488828
##on test data## rmse loss: 1940.3118915264422, mae loss: 1227.0070176344652, mape loss: 611.8161490788826

2024-07-15 20:52:16.748 | INFO     | __main__:main:190 - =====Epoch 3=====

##on train data## total loss: 0.051616647001828636, pred loss: 0.045165320793355855, regression loss: 0.006451326208472781 
##on train data## rmse loss: 2200.9073300434247, mae loss: 1073.7363789359931, mape loss: 3014.13659777133
##on valid data## rmse loss: 1692.3600618802584, mae loss: 1025.6203073354868, mape loss: 583.9484987350611
##on test data## rmse loss: 1881.9247089092548, mae loss: 1140.596872652494, mape loss: 339.3884704204706

2024-07-15 20:53:45.986 | INFO     | __main__:main:190 - =====Epoch 4=====

##on train data## total loss: 0.04813167162069361, pred loss: 0.042931210188795504, regression loss: 0.0052004614318981015 
##on train data## rmse loss: 2149.2610811340023, mae loss: 1102.6376184763642, mape loss: 7059.080501074718
##on valid data## rmse loss: 1662.7132305438702, mae loss: 1050.9458186222957, mape loss: 1198.549619592153
##on test data## rmse loss: 1860.646573110727, mae loss: 1167.0224290114184, mape loss: 605.8750814657944

2024-07-15 20:55:37.320 | INFO     | __main__:main:190 - =====Epoch 5=====

##on train data## total loss: 0.04663625186980527, pred loss: 0.04195624194344326, regression loss: 0.00468000992636201 
##on train data## rmse loss: 2056.0183043504126, mae loss: 1018.7286014460065, mape loss: 2233.834016746676
##on valid data## rmse loss: 1604.9781315730168, mae loss: 951.0275803786058, mape loss: 459.8415651688209
##on test data## rmse loss: 1809.1160682091347, mae loss: 1084.9519911545974, mape loss: 424.98437212063715

2024-07-15 20:57:06.834 | INFO     | __main__:main:190 - =====Epoch 6=====

##on train data## total loss: 0.044902753524557894, pred loss: 0.040779057073496695, regression loss: 0.004123696451061192 
##on train data## rmse loss: 2059.43860235069, mae loss: 1090.0105188050245, mape loss: 1923.5802322172271
##on valid data## rmse loss: 1634.5133000300482, mae loss: 993.6046250563402, mape loss: 224.70137974390616
##on test data## rmse loss: 1803.4587571364182, mae loss: 1104.1003910945012, mape loss: 230.31945989682123

2024-07-15 20:58:36.477 | INFO     | __main__:main:190 - =====Epoch 7=====

##on train data## total loss: 0.045375140412204765, pred loss: 0.04121981215424514, regression loss: 0.00415532825795962 
##on train data## rmse loss: 2030.9376133952649, mae loss: 1036.130429340498, mape loss: 4030.82117961748
##on valid data## rmse loss: 1564.040815617488, mae loss: 948.4004408616286, mape loss: 564.9809156931364
##on test data## rmse loss: 1736.4675541804388, mae loss: 1058.257861328125, mape loss: 355.9701542212413

2024-07-15 21:00:06.018 | INFO     | __main__:main:190 - =====Epoch 8=====

##on train data## total loss: 0.04474703367175487, pred loss: 0.04060651580117605, regression loss: 0.004140517870578821 
##on train data## rmse loss: 2095.677451196661, mae loss: 1022.1840333890189, mape loss: 3671.908867631467
##on valid data## rmse loss: 1629.7852407602163, mae loss: 989.4122713529147, mape loss: 825.1945523573802
##on test data## rmse loss: 1828.0518498347355, mae loss: 1112.0565950833834, mape loss: 432.3902087486707

2024-07-15 21:01:58.487 | INFO     | __main__:main:190 - =====Epoch 9=====

##on train data## total loss: 0.0433964146972459, pred loss: 0.039580091240763816, regression loss: 0.0038163234564820825 
##on train data## rmse loss: 2005.3129123745837, mae loss: 1002.0747206634676, mape loss: 1864.4650160358642
##on valid data## rmse loss: 1603.3796499399039, mae loss: 941.7111532358023, mape loss: 354.5314868138387
##on test data## rmse loss: 1795.7437039888823, mae loss: 1067.8179124098558, mape loss: 306.52252999635846

2024-07-15 21:03:26.957 | INFO     | __main__:main:190 - =====Epoch 10=====

##on train data## total loss: 0.04306723193033849, pred loss: 0.03932718563763434, regression loss: 0.0037400462927041473 
##on train data## rmse loss: 2017.6321823197572, mae loss: 1015.6637263419059, mape loss: 1398.2901216460968
##on valid data## rmse loss: 1610.155859375, mae loss: 944.3106651893029, mape loss: 383.51768805430487
##on test data## rmse loss: 1791.5820354755108, mae loss: 1063.396616774339, mape loss: 285.4087550135759

2024-07-15 21:04:55.689 | INFO     | __main__:main:190 - =====Epoch 11=====

##on train data## total loss: 0.042326641888334064, pred loss: 0.03865363298995694, regression loss: 0.003673008898377116 
##on train data## rmse loss: 2019.9459420605965, mae loss: 1004.1087792101246, mape loss: 1925.557530501167
##on valid data## rmse loss: 1582.7770094651441, mae loss: 929.9703866811899, mape loss: 302.7336979829348
##on test data## rmse loss: 1756.4029963566707, mae loss: 1043.7929368239184, mape loss: 225.14816935245807

2024-07-15 21:06:24.311 | INFO     | __main__:main:190 - =====Epoch 12=====

##on train data## total loss: 0.042812102086615136, pred loss: 0.038972671401360764, regression loss: 0.003839430685254372 
##on train data## rmse loss: 2017.3419276203601, mae loss: 1062.885573333895, mape loss: 5521.050000553809
##on valid data## rmse loss: 1602.2148493840143, mae loss: 993.1575068547176, mape loss: 855.7237041913546
##on test data## rmse loss: 1785.9250225360577, mae loss: 1111.3473660982572, mape loss: 542.6425646818601

2024-07-15 21:07:52.912 | INFO     | __main__:main:190 - =====Epoch 13=====

##on train data## total loss: 0.041997514702947006, pred loss: 0.038498586135606756, regression loss: 0.003498928567340248 
##on train data## rmse loss: 1998.086116577768, mae loss: 951.2884530779069, mape loss: 2623.873309072504
##on valid data## rmse loss: 1582.357184776893, mae loss: 919.8497450608473, mape loss: 453.8913391645138
##on test data## rmse loss: 1777.4389869103065, mae loss: 1041.6754629281852, mape loss: 202.10329202505258

2024-07-15 21:09:21.793 | INFO     | __main__:main:190 - =====Epoch 14=====

##on train data## total loss: 0.04162229270423729, pred loss: 0.03820748119656384, regression loss: 0.0034148115076734517 
##on train data## rmse loss: 1955.0450656329315, mae loss: 931.6718322444083, mape loss: 1768.7999476030998
##on valid data## rmse loss: 1547.679854642428, mae loss: 896.5642500657302, mape loss: 394.5921632418266
##on test data## rmse loss: 1742.3294499323918, mae loss: 1020.2645010141226, mape loss: 239.51839025203998

2024-07-15 21:10:50.965 | INFO     | __main__:main:190 - =====Epoch 15=====

##on train data## total loss: 0.04098785840693464, pred loss: 0.03763627227860252, regression loss: 0.003351586128332118 
##on train data## rmse loss: 1987.2396503584034, mae loss: 973.7147551405853, mape loss: 4709.911948623996
##on valid data## rmse loss: 1592.3912907527044, mae loss: 939.2444115271935, mape loss: 547.0637158705638
##on test data## rmse loss: 1799.6187852125902, mae loss: 1068.982119516226, mape loss: 213.51158481377823

2024-07-15 21:12:20.127 | INFO     | __main__:main:190 - =====Epoch 16=====

##on train data## total loss: 0.04058001623465325, pred loss: 0.03735486994323742, regression loss: 0.003225146291415836 
##on train data## rmse loss: 1945.22656745717, mae loss: 944.20093517013, mape loss: 4523.247410440203
##on valid data## rmse loss: 1553.8042325533354, mae loss: 911.7139516977163, mape loss: 667.087084696843
##on test data## rmse loss: 1730.9346595177283, mae loss: 1018.7104679987981, mape loss: 316.64057351075684

